import streamlit as st
import os
import torch
from transformers import pipeline as hf_pipeline
from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv
import tempfile

# ุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ (ููุงุชูุญ API)
load_dotenv()

# ุฅุนุฏุงุฏ ุงูุตูุญุฉ
st.set_page_config(page_title="ูุญูู ุงูุฎุทุงุจุงุช", layout="centered")
st.title("๐๏ธ ูููู ุชุญููู ุงูุฎุทุงุจุงุช ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู")
st.write("ุงุฑูุน ูููุงู ุตูุชูุงู ูุฎุทุงุจ ุฃู ุฅููุงุกุ ูุงุญุตู ุนูู ุชูุฑูุฑ ููุตู ููุตุงุฆุญ ูุชุญุณูู ุงูุฃุฏุงุก.")

# ุชุญููู ุงูููุงุฐุฌ ูุฑุฉ ูุงุญุฏุฉ ูู ุจุฏุงูุฉ ุงูุชุดุบูู ูุชุณุฑูุน ุงูุนูููุงุช ุงููุงุญูุฉ
@st.cache_resource
def load_models():
    """ุชุญููู ุงูููุงุฐุฌ ุงูุซูููุฉ ูุฑุฉ ูุงุญุฏุฉ ูุชุฎุฒูููุง ูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ"""
    groq_api_key = os.getenv("GROQ_API_KEY")
    if not groq_api_key:
        st.error("ููุชุงุญ Groq API ุบูุฑ ููุฌูุฏ! ูุฑุฌู ุฅุนุฏุงุฏู ูู ูุชุบูุฑุงุช ุงูุจูุฆุฉ.")
        st.stop()
    
    llm = ChatGroq(model="llama-3.1-8b-instant", api_key=groq_api_key)
    
    device = 0 if torch.cuda.is_available() else -1
    asr_pipeline = hf_pipeline(
        "automatic-speech-recognition",
        model="openai/whisper-base",
        device=device
    )
    return llm, asr_pipeline

llm, asr_pipeline = load_models()

# ุงููุธุงุฆู ุงูุฃุณุงุณูุฉ (ููุณูุง ูู Colab ูุน ุชุนุฏููุงุช ุจุณูุทุฉ)
def transcribe_audio(audio_file_path):
    """ุชุญููู ุงูุตูุช ุฅูู ูุต"""
    result = asr_pipeline(audio_file_path, return_timestamps=True, chunk_length_s=30, stride_length_s=5)
    transcript = "".join(chunk['text'] for chunk in result['chunks'])
    return transcript.strip()

def analyze_and_generate_report(transcript):
    """ุชุญููู ุงููุต ูุชูููุฏ ุงูุชูุฑูุฑ"""
    prompt_template = """
    ุฃูุช ุฎุจูุฑ ูุชุฎุตุต ูู ูู ุงูุฎุทุงุจุฉ. ูู ุจุชุญููู ุงููุต ุงูุชุงูู ูุชูุฏูู ุชูุฑูุฑ ููุตู.
    **ูุต ุงูุฎุทุงุจ:** {transcript}
    **ุงูุชูุฑูุฑ (ุจุงููุบุฉ ุงูุนุฑุจูุฉ):**
    1.  **ููุฎุต ุนุงู:**
    2.  **ููุงุท ุงูููุฉ:**
    3.  **ูุฌุงูุงุช ุงูุชุญุณูู:**
    4.  **ุงููููุงุช ุงูููุกุฆุฉ (Filler Words):**
    5.  **ูููู ุงูุฎุทุงุจ:**
    6.  **ูุตุงุฆุญ ุนูููุฉ ูุงุจูุฉ ููุชุทุจูู:**
    """
    prompt = PromptTemplate.from_template(prompt_template)
    chain = prompt | llm
    report = chain.invoke({"transcript": transcript})
    return report.content

# --- ุงููุงุฌูุฉ ุงูุฑุฆูุณูุฉ ููุชุทุจูู ---

# 1. ูููู ุฑูุน ุงููููุงุช
uploaded_file = st.file_uploader("ุงุฎุชุฑ ูููุงู ุตูุชูุงู (MP3, WAV, M4A)", type=["mp3", "wav", "m4a"])

if uploaded_file is not None:
    st.audio(uploaded_file, format='audio/mp3')
    st.success(f"ุชู ุฑูุน ุงูููู: {uploaded_file.name}")

    # 2. ุฒุฑ ุจุฏุก ุงูุชุญููู
    if st.button("๐ ุญูู ุงูุฎุทุงุจ ุงูุขู"):
        with st.spinner("ุฌุงุฑู ุชุญููู ุงูุตูุช ุฅูู ูุต... ูุฏ ูุณุชุบุฑู ูุฐุง ุจุนุถ ุงูููุช."):
            # ุญูุธ ุงูููู ุงููุฑููุน ูุคูุชุงู ุนูู ุงููุฑุต
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmpfile:
                tmpfile.write(uploaded_file.getvalue())
                tmpfile_path = tmpfile.name
            
            # ุชุญููู ุงูุตูุช ุฅูู ูุต
            transcript = transcribe_audio(tmpfile_path)
            st.subheader("๐ ุงููุต ุงููุณุชุฎุฑุฌ ูู ุงูุฎุทุงุจ:")
            st.write(transcript)

        with st.spinner("ุฌุงุฑู ุชุญููู ุงููุต ูุชูููุฏ ุงูุชูุฑูุฑ..."):
            # ุชุญููู ุงููุต
            final_report = analyze_and_generate_report(transcript)
            
            # ุนุฑุถ ุงูุชูุฑูุฑ ุงูููุงุฆู
            st.subheader("๐ ุงูุชูุฑูุฑ ุงูููุงุฆู ูุงููุตุงุฆุญ:")
            st.markdown(final_report)